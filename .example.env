# Example .env for the PyPI ingestion pipeline
# ---------------------------------------------
# Copy this file to `.env` and edit the values below. Do NOT commit
# your real `.env` file to version control â€” it may contain credentials
# or sensitive configuration.

# START_DATE: Inclusive start date for the query window. Format: YYYY-MM-DD
# Used to build the BigQuery WHERE clause: timestamp >= START_DATE
START_DATE=2025-10-01

# END_DATE: Exclusive end date for the query window. Format: YYYY-MM-DD
# Used to build the BigQuery WHERE clause: timestamp < END_DATE
END_DATE=2025-10-10

# PYPI_PROJECT: The name of the PyPI project/package to filter on (e.g. requests).
# This maps to the `project` column in the PyPI downloads table.
PYPI_PROJECT=example-package

# TABLE_NAME: Fully-qualified BigQuery table to query. Examples:
#   - Public PyPI downloads: bigquery-public-data.pypi.file_downloads
#   - Your own table: your-project.your_dataset.your_table
TABLE_NAME=bigquery-public-data.pypi.file_downloads

# GCP_PROJECT: Google Cloud project ID where the job should run / where
# temporary resources are billed. Replace with your project ID.
GCP_PROJECT=your-gcp-project-id

# TIMESTAMP_COLUMN: Column name in the table used for time-based filtering.
# Default in the code is `timestamp` for the public PyPI downloads table.
TIMESTAMP_COLUMN=timestamp

# DESTINATION: One or more destinations to write results to. Comma-separated
# values are accepted. Valid options (example): local, gcs, s3, md
# Example: DESTINATION=local,gcs
DESTINATION=local

# S3_PATH: If you include 's3' in DESTINATION, set the S3 path here (e.g. s3://my-bucket/path).
# Leave empty if not using S3.
S3_PATH=

# AWS_PROFILE: Optional AWS CLI profile to use for S3 access. Leave empty if not needed.
AWS_PROFILE=

# GOOGLE_APPLICATION_CREDENTIALS: Path to a GCP service account JSON key file.
# The BigQuery client uses this environment variable for authentication. If
# you prefer, set this env var to point to your credentials file, or configure
# application default credentials using gcloud.
GOOGLE_APPLICATION_CREDENTIALS=

# NOTES:
# - Do not wrap values in quotes in this file. Use plain, unquoted values.
# - Required values: START_DATE, END_DATE, PYPI_PROJECT, TABLE_NAME, GCP_PROJECT,
#   TIMESTAMP_COLUMN, and DESTINATION. The pipeline will raise an error if
#   any required values are missing.
# - After editing, create a runtime `.env` by copying this file:
#     cp .example.env .env